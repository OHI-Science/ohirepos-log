# This is prep_col.Rmd


## 0. add col to `sc_studies_custom.csv` 

Add by hand to `ohi-webapps/custom/sc_studies_custom.csv`

## 1. setup
```{r setup, eval=F}

# libraries
library(dplyr)
library(rgdal)

# directories
dir_M <- c('Windows' = '//mazu.nceas.ucsb.edu/ohi',
           'Darwin'  = '/Volumes/ohi',
           'Linux'   = '/home/shares/ohi')[[ Sys.info()[['sysname']] ]]
dir_custom_col = '~/github/ohi-webapps/custom/col'

# setwd
setwd('~/github/ohi-webapps')

```

## 2. maps
```{r setup, eval=F}

# read in shp files and save with desired headers in data frame.
col = rgdal::readOGR(dsn = file.path(dir_annex, 'col/spatial/custom/raw'),
              layer = 'Limites_marinos_planas')

# view dataframe and map
col@data
plot(col)

## change to km2 
col@data <- col@data %>%
  dplyr::mutate(area_km2 = area_hecta * 0.01) %>%
  dplyr::select(rgn_id, rgn_name, area_km2)

# save as shapefiles. will create 4 files: .dbf, .prj, .shp, .shx
writeOGR(col, dsn = file.path(dir_annex, 'col/spatial/custom'), 
         layer = 'col_shp', driver = 'ESRI Shapefile', overwrite=T) 

## ave/rgn_offshore_data.csv on git-annex
write.csv(col@data, file.path(dir_annex, 'col/spatial', 'rgn_offshore_data.csv'))

# create lookup table with unique rgn_ids
col_rgns = col@data
write_csv(col_rgns, '~/github/ohi-webapps/custom/col/col_rgns_custom.csv')

```


## 3. prep col map with custom_maps()
Proceed as in `create_all.r` and run `custom_maps()`

```{r prep col map custom_maps, eval=FALSE}

keys_redo = 'col'
key = keys_redo[1]

setwd(dir_repos)
source(sprintf('%s/ohi-webapps/create_init_sc.R', dir_github))
setwd(dir_repo)

# fun custom_maps
custom_maps(key) 

```


## 4. col layers: bind possible layers for col


```{r col layers: bind from col-xxx repos, eval=F}

# clone existing col repo
key = 'col'
setwd(dir_repos)
source(sprintf('%s/ohi-webapps/create_init_sc.R', dir_github))

setwd(dir_repos)
unlink(dir_repo, recursive=T, force=T)
repo = clone(git_url, normalizePath(dir_repo, mustWork=F))

lkp = read.csv('~/github/ohi-webapps/custom/col/col_rgns_custom.csv')


## delete/unlink problem layers, dealt with separately in next step
tounlink = c('lsp_prot_area_inland1km_gl2014.csv',      # lsp layers 
             'lsp_prot_area_offshore3nm_gl2014.csv',
             'rgn_area_inland1km_sc2014-area.csv',
             'rgn_area_offshore3nm_sc2014-area.csv',
             'rgn_area_sc2014-area.csv')
for (f in tounlink) {
  unlink(file.path(dir_repos, 'col/subcountry2014/layers', f), 
         recursive=T, force=T)
}

# list all layers to copy to col repo
lyrs_list = list.files(file.path(dir_repos, 'col/subcountry2014/layers'), # was orignally subcountry2014
                       glob2rx('*.csv'), full.names=T) 


# loop through all layers, all col repos to create correct # of regions per col layer
for (f in lyrs_list){ # f = lyrs_list[1]
  
  cat(sprintf('processing %s ... \n', basename(f)))
  
  # read in layer, save names, delete all but headers (a bit hacky this way)
  lyr_tmp = read_csv(f)
  lyr_col = names(lyr_tmp)
  
  # only works for rgn_ids; FIS layers different
  if ('rgn_id' %in% lyr_col){
    
    # delete all data in layer
    lyr_bind = lyr_tmp %>%
      filter(rgn_id == 0)
    
    default_scenario = 'subcountry2014'
    
    # read in b's layer
    s = read_csv(file.path(dir_repo, default_scenario, 'layers', basename(f)))
    
    # make sure classes are correct; was a problem for ico_spp_extinction_status_gl2014.csv. 
    # See http://stackoverflow.com/questions/27361081/r-assign-or-copy-column-classes-from-a-data-frame-to-another
    s[] = mapply(FUN = as, s, sapply(lyr_tmp, class), SIMPLIFY=F)
    
    
    if ('area_km2' %in% lyr_col) s = s %>% select(-area_km2) # use area_km2 from lkp_b (regions) not s (nations)
    if ('rgn_name' %in% lyr_col) s = s %>% select(-rgn_name) # use rgn_name from lkp_b (regions) not s (nations)
    
    # join lookup with layer, select orig columns using non-standard evaluation, ie dplyr::*_()
    t = s %>%
      # rename(sc_id = rgn_id) %>%
      right_join(lkp, by='rgn_id') %>%
      select_(.dots = lyr_col)
    
    # save file
    lyr_save = t %>%
      arrange(rgn_id)
    write_csv(lyr_save, f)
    
  } else {
    cat(sprintf('layer does not have rgn_id variable, do separately: %s', f))
  }
}

```

## 5. col layers: handle problem layers 

Handle several problem layers individually 

```{r col_layers: handle individuals, eval=FALSE}

dir_col_lyrs = file.path(dir_repos, 'col/subcountry2014/layers')
l_csv = file.path(dir_repos, 'col/subcountry2014/layers.csv')

# recreate rgn_global_gl2014.csv
lkp %>% select(rgn_id, label = rgn_name) %>%
  write_csv(file.path(dir_col_lyrs, 'rgn_global_gl2014.csv'))

# recreate rgn_labels.csv 
lkp %>% mutate(type = 'eez') %>%
  select(rgn_id, type, label = rgn_name) %>%
  write_csv(file.path(dir_col_lyrs, 'rgn_labels.csv'))


# recreate rgn_area_sc2014-area.csv
lkp %>% select(rgn_id, rgn_name, area_hecta) %>%
  write_csv(file.path(dir_col_lyrs, 'rgn_area_sc2014-area.csv'))
readLines(l_csv, warn=F, encoding='UTF-8') %>%
 
## BY HAND:: need to change all area_km2 to area_hecta  


# recreate rgn_area_inland1km_gl2014.csv and rgn_area_offshore3nm_gl2014.csv
tmp = lkp %>%
  select(rgn_id) %>%
  mutate(area_km2 = 5) # placeholder
write_csv(tmp, file.path(dir_col_lyrs, 'rgn_area_inland1km_placeholder.csv'))
write_csv(tmp, file.path(dir_col_lyrs, 'rgn_area_offshore3nm_placeholder.csv'))
readLines(l_csv, warn=F, encoding='UTF-8') %>%
  str_replace("rgn_area_inland1km_sc2014-area.csv", 
              "rgn_area_inland1km_placeholder.csv") %>%
  str_replace("rgn_area_offshore3nm_sc2014-area.csv", 
              "rgn_area_offshore3nm_placeholder.csv") %>%
  writeLines(l_csv)


# recreate lsp_prot_area_inland1km_gl2014.csv and lsp_prot_area_offshore3nm_gl2014.csv
tmp_yrs = 2010:2015
tmp = data.frame(rgn_id = rep(1:dim(lkp)[1], length(tmp_yrs))) %>%
  arrange(rgn_id) %>%
  mutate(year = rep(tmp_yrs, dim(lkp)[1]), 
         area_km2 = 10)
write_csv(tmp, file.path(dir_col_lyrs, 'lsp_prot_area_inland1km_placeholder.csv'))
write_csv(tmp, file.path(dir_col_lyrs, 'lsp_prot_area_offshore3nm_placeholder.csv'))
# update layers.csv
readLines(l_csv, warn=F, encoding='UTF-8') %>%
  str_replace("lsp_prot_area_inland1km_gl2014.csv", 
              "lsp_prot_area_inland1km_placeholder.csv") %>%
  str_replace("lsp_prot_area_offshore3nm_gl2014.csv", 
              "lsp_prot_area_offshore3nm_placeholder.csv") %>%
  writeLines(l_csv)


# recreate rgn_georegions_gl2014.csv very hacky 
tmp = read_csv(file.path(dir_col_lyrs, 'rgn_georegions_gl2014.csv')) %>%
  select(-rgn_id) %>%
  distinct()
tmp2 = bind_rows(
  data.frame(rgn_id = 1:dim(lkp)[1]) %>%
    mutate(level = tmp$level[1]) %>%
    mutate(georgn_id = tmp$georgn_id[1]), 
  data.frame(rgn_id = 1:dim(lkp)[1]) %>%
    mutate(level = tmp$level[2]) %>%
    mutate(georgn_id = tmp$georgn_id[2]),
  data.frame(rgn_id = 1:dim(lkp)[1]) %>%
    mutate(level = tmp$level[3]) %>%
    mutate(georgn_id = tmp$georgn_id[3]))
write_csv(tmp2, file.path(dir_col_lyrs, 'rgn_georegions_gl2014.csv'))


# recreate rgn_georegion_labels_gl2014.csv
tmp = read_csv(file.path(dir_col_lyrs, 'rgn_georegion_labels_gl2014.csv')) %>%
  select(-rgn_id) %>%
  distinct()
tmp2 = bind_rows(
  data.frame(rgn_id = 1:dim(lkp)[1]) %>%
    mutate(level = tmp$level[1]) %>%
    mutate(label = tmp$label[1]), 
  data.frame(rgn_id = 1:dim(lkp)[1]) %>%
    mutate(level = tmp$level[2]) %>%
    mutate(label = tmp$label[2]),
  data.frame(rgn_id = 1:dim(lkp)[1]) %>%
    mutate(level = tmp$level[3]) %>%
    mutate(label = tmp$label[3]))
write_csv(tmp2, file.path(dir_col_lyrs, 'rgn_georegion_labels_gl2014.csv'))


# overwrite np_harvest_product_weight_gl2014.csv layer; update layers.csv 
# see https://github.com/OHI-Science/issues/issues/407#issuecomment-96237694
tmp_prod = c('fish_oil', 'ornamentals', 'seaweeds', 'shells', 'sponges')
data.frame(rgn_id = rep(1:dim(lkp)[1], length(tmp_prod))) %>%
  arrange(rgn_id) %>%
  mutate(product = rep(tmp_prod, dim(lkp)[1]),
         weight  = 0.2) %>%
  write_csv(file.path(dir_col_lyrs, 'np_harvest_product_weight_placeholder.csv'))

l_csv = file.path(dir_repos, 'col/subcountry2014/layers.csv')
readLines(l_csv, warn=F, encoding='UTF-8') %>%
  str_replace("np_harvest_product_weight_gl2014.csv", 
              "np_harvest_product_weight_placeholder.csv") %>%
  writeLines(l_csv)

```


## 6. populate_draft_branch() spatial

overwrite existing json and geojson files with new maps from `populate_draft_branch()`


```{r populate_draft_branch spatial, eval=F}

key = 'col'
setwd(dir_repos)
source(sprintf('%s/ohi-webapps/create_init_sc.R', dir_github))
setwd(dir_repo)

# from populate_draft_branch, ~L333
f_js_old      = file.path(dir_annex_sc, 'regions_gcs.js')
f_geojson_old = file.path(dir_annex_sc, 'regions_gcs.geojson')
f_js          = file.path(dir_annex_sc, 'spatial', 'regions_gcs.js')
f_geojson     = file.path(dir_annex_sc, 'spatial', 'regions_gcs.geojson')
if (file.exists(f_js_old)) file.rename(f_js_old, f_js)
if (file.exists(f_geojson_old)) file.rename(f_geojson_old, f_geojson)
txt_shp_error = sprintf('%s/%s_shp_to_geojson.txt', dir_errors, key)
unlink(txt_shp_error)
if (!file.exists(f_js)){                                              
  f_shp = file.path(dir_annex, key, 'spatial', 'rgn_offshore_gcs.shp')
  cat(sprintf('  shp_to_geojson -- %s\n', format(Sys.time(), '%X')))
  v = try(shp_to_geojson(f_shp, f_js, f_geojson))
  if (class(v)=='try-error'){
    cat(as.character(traceback(v)), file=txt_shp_error)
    next
  }
}
for (f in c(f_js, f_geojson)){ # f = f_spatial[1]
  if (key != 'col')  file.copy(f, sprintf('spatial/%s', basename(f)), overwrite=T) # original
  if (key == 'col') file.copy(f, sprintf('subcountry2014/spatial/%s', basename(f)), overwrite=T) # col
  cat(sprintf('copying from %s', f))
}
 
```

## 7. populate_draft_branch() config.r

Reset map's zoom center in `config.r`
(Note: no need to also overwrite `.travis.yml` since based on existing `col` repo)

```{r populate_draft_branch config.r, eval=F}
    
key = 'col'
setwd(dir_repos)
source(sprintf('%s/ohi-webapps/create_init_sc.R', dir_github))
setwd(dir_repo)

# from populate_draft_branch ~ L647
f_in  = file.path(dir_repos, 'col', 'subcountry2014/conf/config.r')
f_out = f_in 

s = readLines(f_in, warn=F, encoding='UTF-8') 

# get map centroid and zoom level
# TODO: http://gis.stackexchange.com/questions/76113/dynamically-set-zoom-level-based-on-a-bounding-box
# var regions_group = new L.featureGroup(regions); map.fitBounds(regions_group.getBounds());
p_shp  = file.path(dir_annex_sc, 'spatial', 'rgn_offshore_gcs.shp')
p      = readOGR(dirname(p_shp), tools::file_path_sans_ext(basename(p_shp)))
p_bb   = data.frame(p@bbox) # max of 2.25
p_ctr  = rowMeans(p_bb)
p_zoom = 12 - as.integer(cut(max(transmute(p_bb, range = max - min)), c(0, 0.25, 0.5, 1, 2.5, 5, 10, 20, 40, 80, 160, 320, 360)))

# set map center and zoom level
s = s %>%
  str_replace("map_lat.*", sprintf('map_lat=%g; map_lon=%g; map_zoom=%d', p_ctr['y'], p_ctr['x'], p_zoom))

# use just rgn_labels (not rgn_global)
s = gsub('rgn_global', 'rgn_labels', s)

writeLines(s, f_out)
 
```


## 8. Test col's calculate_scores.r

Make sure no errors in calculating goal scores. 

```{r test col calculate_scores, eval=F}

setwd(file.path(dir_repos, 'col', 'subcountry2014'))

# load scenario configuration
conf = Conf('conf')

# run checks on scenario layers
CheckLayers('layers.csv', 'layers', flds_id=conf$config$layers_id_fields)

# load scenario layers
layers = Layers('layers.csv', 'layers')

# calculate scenario scores
scores = CalculateAll(conf, layers, debug=F)
write.csv(scores, 'scores.csv', na='', row.names=F) # save goal scores

```

## 9. Final create_all.r fxns (altered)

Run these with `ohi-functions.r`, not `ohi-travis-functions.r`. The function order below is from `create_all.r`; some functions from `ohi-functions.r` not `ohi-travis-functions.r`

```{r final create_all fxns, eval=F}

key = 'col'
setwd(dir_repos)
source(sprintf('%s/ohi-webapps/create_init_sc.R', dir_github))
source(sprintf('%s/ohi-webapps/ohi-functions.r', dir_github)) 
setwd(dir_repo)


## function order from create_all.r; some functions from `ohi-functions.r` 

# push draft branch ~ adapted from create.all
setwd(dir_repo)
push_branch('draft') # source('ohi-functions.r')
system('git pull')


# populate website and update_webapp_notravis (which calls 
   # 1. calculate_scores_notravis()
   # 2. update_results()
   # 3. merge_published_draft()
   # 4. update_pages()
update_website(key)
update_webapp_notravis(key, run_calc_scores=T, run_update_results=T, merge_pub=T)
system('git checkout gh-pages; git pull; git checkout published; git pull')


## deploy app to fitz!
deploy_app_nceas(key, nceas_user)
system('git checkout draft; git pull')

# might have to run from terminal:
# ssh jstewart@fitz.nceas.ucsb.edu
# cd /srv/shiny-server
# sudo chown -R jstewart /srv/shiny-server
# sudo service shiny-server restart

```


